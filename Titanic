import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold

data_train = pd.read_csv(r'C:\****\KAGGLE_TITANIC\train.csv')
data_train.head()
data_train.info()
data_train['Age'] = data_train['Age'].fillna(data_train['Age'].median())
data_train.describe()
# The Age column has been filled
# Count each element
ans = data_train['Embarked'].value_counts()
# return max index
fillstr = ans.idxmax()

data_train['Embarked'] = data_train['Embarked'].fillna(fillstr)
data_train.info()
# You could see the Embarked column has been filled
# Use loc to locate row
data_train.loc[data_train["Sex"] == "male", "Sex"] = 0
data_train.loc[data_train["Sex"] == "female", "Sex"] = 1
data_train.loc[data_train['Embarked'] == 'C', 'Embarked'] = 0
data_train.loc[data_train['Embarked'] == 'Q', 'Embarked'] = 1
data_train.loc[data_train['Embarked'] == 'S', 'Embarked'] = 2
train_corr = data_train.drop('PassengerId', axis=1).corr()

# Heatmap
a = plt.subplots(figsize=(15, 9))
a = sns.heatmap(train_corr, vmin=-1, vmax=1, annot=True, square=True)  # Heatmap

predictors = ["Pclass", "Age", "Parch", "Fare", "Sex", "Embarked", 'SibSp']

# Initiate linear regression.
alg = LinearRegression()
# Kfold split to 3 sets.
kf = KFold(n_splits=3, shuffle=False, random_state=1)
predictions = []
for train, test in kf.split(data_train):
    train_predictors = (data_train[predictors].iloc[train, :])
    train_target = data_train["Survived"].iloc[train]
    alg.fit(train_predictors, train_target)
    test_predictions = alg.predict(data_train[predictors].iloc[test, :])
    predictions.append(test_predictions)
# Test Accuracy
predictions = np.concatenate(predictions, axis=0)
predictions[predictions > .5] = 1
predictions[predictions <= .5] = 0
accuracy = sum(predictions == data_train["Survived"]) / len(predictions)
print("The accuracy is: ", accuracy)

# Repeat Pre-processing the same as training data.

data_test = pd.read_csv(r'C:\****\KAGGLE_TITANIC\test.csv')

ans = data_test['Embarked'].value_counts()

# Return Max Index.
fillstr = ans.idxmax()

data_test['Embarked'] = data_test['Embarked'].fillna(fillstr)
data_test.info()
data_test.loc[data_test["Sex"] == "male", "Sex"] = 0
data_test.loc[data_test["Sex"] == "female", "Sex"] = 1
data_test.loc[data_test['Embarked'] == 'C', 'Embarked'] = 0
data_test.loc[data_test['Embarked'] == 'Q', 'Embarked'] = 1
data_test.loc[data_test['Embarked'] == 'S', 'Embarked'] = 2

data_test['Age'] = data_test['Age'].fillna(data_test['Age'].median())

mid = data_test['Fare'].median()
data_test['Fare'] = data_test['Fare'].fillna(value=mid)

test_predictions = alg.predict(data_test[predictors])
test_predictions[test_predictions >= 0.5] = 1
test_predictions[test_predictions < 0.5] = 0

# Get result.
result = pd.DataFrame(
    {'PassengerId': data_test['PassengerId'].as_matrix(), 'Survived': test_predictions.astype(np.int32)})
# Export as CSV.
result.to_csv(r'C:\****\KAGGLE_TITANIC\result.csv')

#Kaggle accuracy - 78.78%
